import whisper
import os
import sounddevice as sd
import scipy.io.wavfile as wav

# ======== sound-device éŒ„éŸ³è¨­å®š ========
DURATION = 5  # éŒ„éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
SAMPLING_RATE = 44100  # æ¨£æœ¬ç‡
CHUNK_DURATION = 0.1  # æ¯æ¬¡éŒ„éŸ³çš„æ™‚é–“é•·åº¦ï¼ˆç§’ï¼‰

# ======== å®šç¾©é¡è‰²ä»£ç¢¼ ========
class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    PURPLE = '\033[95m'
    CYAN = '\033[96m'
    RESET = '\033[0m'

# ======== è½‰æ›æ–‡å­—é¡è‰² ========
def to_color(color_code, text):
    return f"{color_code}{text}{Colors.RESET}"

# ======== éŒ„éŸ³ ========
def record_audio():
    print(to_color(Colors.GREEN, "ğŸŸ¢ å–µ~é–‹å§‹éŒ„éŸ³å›‰! è«‹å°è‘—éº¥å…‹é¢¨èªªè©±..."))
    audio_data = sd.rec(int(DURATION * SAMPLING_RATE), samplerate=SAMPLING_RATE, channels=1, dtype='int16')
    sd.wait()
    print(to_color(Colors.GREEN, "âœ… éŒ„éŸ³å®Œæˆ! å–µ~"))
    return audio_data

# ======== ä¿å­˜éŸ³é » ========
def save_audio(audio_data, filename):
    wav.write(filename, SAMPLING_RATE, audio_data)
    print(to_color(Colors.GREEN, "âœ… å–µ~éŸ³é »å·²ä¿å­˜"), to_color(Colors.BLUE, f"æª”å: {filename}"))

# ======== èªéŸ³è¾¨è­˜(Speech-to-Text) ========
def transcribe_audio(filename):
    if os.path.exists(filename):
        model = whisper.load_model("base")
        result = model.transcribe(filename, language="zh")
        return result["text"]
    else:
        print(to_color(Colors.RED, "âŒ å–µå—šå—šæ‰¾ä¸åˆ°éŸ³æª”: "), to_color(Colors.BLUE, filename))
        return None

# ======== ä¸»ç¨‹å¼ ========

# æª¢æŸ¥éŸ³é »æ–‡ä»¶è·¯å¾‘
FILE_NAME = "./audio/test1.wav"

audio_data = record_audio()
save_audio(audio_data, FILE_NAME)
result = transcribe_audio(FILE_NAME)

if result:
    print(to_color(Colors.PURPLE, "âœ… å–µ~ è¾¨è­˜æˆåŠŸ!"), to_color(Colors.BLUE, f"çµæœ: {result}"))
else:
    print(to_color(Colors.RED, "âŒ å–µ! è¾¨è­˜å¤±æ•—!!"))
