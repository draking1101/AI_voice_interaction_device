import whisper
import os
import sounddevice as sd
import scipy.io.wavfile as wav
from dotenv import load_dotenv
from openai import OpenAI
import json
from TTS.api import TTS
from playsound import playsound

load_dotenv(dotenv_path=".env")

# ======== å–å¾—ç’°å¢ƒè®Šé‡ ========
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CUSTOM_ROLE = open("./role/role_config.txt", "r", encoding="utf-8").read()

# ======== åˆå§‹åŒ– ========
client = OpenAI(api_key=OPENAI_API_KEY)
tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2") # èªéŸ³æ¨¡å‹, default: model_name="tts_models/multilingual/multi-dataset/xtts_v2"

# ======== sound-device éŒ„éŸ³è¨­å®š ========
DURATION = 5  # éŒ„éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
SAMPLING_RATE = 44100  # æ¨£æœ¬ç‡, default: 44100
FILE_NAME = "./audio/input.wav"
MEMORY_FILE = "./role/role_memory.json"

# ======== TTS è¨­å®š ========
TTS_SPEAKER_WAV = "./audio/speaker.mp3" # æ¨¡ä»¿èªéŸ³
TTS_LANGUAGE = "zh" # èªè¨€, default: "zh"
TTS_OUTPUT_FILE = "./audio/output.wav" # è¼¸å‡ºéŸ³æª”
TTS_TEMPERATURE = 0.3 # æ§åˆ¶éš¨æ©Ÿæ€§

# ======== å®šç¾©é¡è‰²ä»£ç¢¼ ========
class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    PURPLE = '\033[95m'
    CYAN = '\033[96m'
    RESET = '\033[0m'

def to_color(color_code, text):
    return f"{color_code}{text}{Colors.RESET}"

# ======== éŒ„éŸ³ ========
def record_audio():
    print(to_color(Colors.GREEN, "ğŸŸ¢ å–µ~é–‹å§‹éŒ„éŸ³å›‰! è«‹å°è‘—éº¥å…‹é¢¨èªªè©±..."))
    audio_data = sd.rec(int(DURATION * SAMPLING_RATE), samplerate=SAMPLING_RATE, channels=1, dtype='int16')
    sd.wait()
    print(to_color(Colors.GREEN, "âœ… éŒ„éŸ³å®Œæˆ! å–µ~"))
    return audio_data

# ======== ä¿å­˜éŸ³é » ========
def save_audio(audio_data, filename):
    wav.write(filename, SAMPLING_RATE, audio_data)
    print(to_color(Colors.GREEN, "âœ… å–µ~éŸ³é »å·²ä¿å­˜"), to_color(Colors.BLUE, f"æª”å: {filename}"))

# ======== èªéŸ³è¾¨è­˜(Speech-to-Text) ========
def transcribe_audio(filename):
    if os.path.exists(filename):
        model = whisper.load_model("base")
        result = model.transcribe(filename, language="zh")
        return result["text"]
    else:
        print(to_color(Colors.RED, "âŒ å–µå—šå—šæ‰¾ä¸åˆ°éŸ³æª”: "), to_color(Colors.BLUE, filename))
        return None

# ======== è¼‰å…¥è¨˜æ†¶æ­·å² ========
def load_memory():
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

# ======== å„²å­˜è¨˜æ†¶æ­·å² ========
def save_memory(memory):
    with open(MEMORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(memory, f, ensure_ascii=False, indent=2)

# ======== å‘¼å« GPT å›æ‡‰ ========
def get_openai_response(history):
    response = client.chat.completions.create(
        model = "gpt-4o",
        messages = history
    )
    return response.choices[0].message.content

# ======== ç”ŸæˆèªéŸ³ ========
def speak(text):
    tts.tts_to_file(
        text=text,
        speaker_wav=TTS_SPEAKER_WAV,
        language=TTS_LANGUAGE,
        file_path=TTS_OUTPUT_FILE,
        split_sentences=True, # é•·å¥åˆ‡åˆ†
        temperature=TTS_TEMPERATURE
    )
    playsound(TTS_OUTPUT_FILE)

# ======== ä¸»ç¨‹å¼ ========
audio_data = record_audio()
save_audio(audio_data, FILE_NAME)

result = transcribe_audio(FILE_NAME)

if result:
    print(to_color(Colors.PURPLE, "âœ… å–µ~ è¾¨è­˜æˆåŠŸ!"), to_color(Colors.BLUE, f"çµæœ: {result}"))

    memory = load_memory()
    if not memory:
        memory.append({"role": "system", "content": CUSTOM_ROLE})
    memory.append({"role": "user", "content": result})

    response = get_openai_response(memory)
    print(to_color(Colors.PURPLE, "âœ… å–µ~ GPT å›æ‡‰:"), to_color(Colors.BLUE, f"{response}"))

    memory.append({"role": "assistant", "content": response})
    save_memory(memory)

    speak(response)
else:
    print(to_color(Colors.RED, "âŒ å–µ! è¾¨è­˜å¤±æ•—!!"))
